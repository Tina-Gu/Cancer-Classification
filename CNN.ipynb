{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75030c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.nasnet import NASNetLarge, NASNetMobile\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32895561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-defined functions\n",
    "#Transfer 'jpg' images to an array IMG\n",
    "def Dataset_loader(DIR, RESIZE, sigmaX=10):\n",
    "    #IMG = []\n",
    "    BIMG = []\n",
    "    MIMG = []\n",
    "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
    "    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n",
    "        PATH = os.path.join(DIR,IMAGE_NAME)\n",
    "        \n",
    "        name, ftype = os.path.splitext(PATH)\n",
    "        #print(name)\n",
    "        if ftype == \".png\":\n",
    "            img = read(PATH)\n",
    "            img = cv2.resize(img, (RESIZE,RESIZE))\n",
    "            if name[26] =='B':\n",
    "                BIMG.append(np.array(img))\n",
    "            elif name[26]== 'M':\n",
    "                MIMG.append(np.array(img))\n",
    "            #IMG.append(np.array(img))\n",
    "    return BIMG, MIMG\n",
    "\n",
    "def build_model(backbone, lr=1e-4):\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=lr),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320f272",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fd6057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [00:17<00:00, 71.63it/s]\n",
      "100%|██████████| 1416/1416 [00:20<00:00, 69.22it/s]\n",
      "100%|██████████| 1354/1354 [00:19<00:00, 69.36it/s]\n",
      "100%|██████████| 1334/1334 [00:19<00:00, 69.24it/s]\n",
      "100%|██████████| 1243/1243 [00:18<00:00, 68.61it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_b_train, f1_m_train = Dataset_loader('data/fold1/train/200X', 224)\n",
    "f1_b_train = np.array(f1_b_train)\n",
    "f1_m_train = np.array(f1_m_train)\n",
    "\n",
    "f2_b_train, f2_m_train = Dataset_loader('data/fold2/train/200X', 224)\n",
    "f2_b_train = np.array(f2_b_train)\n",
    "f2_m_train = np.array(f2_m_train)\n",
    "\n",
    "f3_b_train, f3_m_train = Dataset_loader('data/fold3/train/200X', 224)\n",
    "f3_b_train = np.array(f3_b_train)\n",
    "f3_m_train = np.array(f3_m_train)\n",
    "\n",
    "f4_b_train, f4_m_train = Dataset_loader('data/fold4/train/200X', 224)\n",
    "f4_b_train = np.array(f4_b_train)\n",
    "f4_m_train = np.array(f4_m_train)\n",
    "\n",
    "f5_b_train, f5_m_train = Dataset_loader('data/fold5/train/200X', 224)\n",
    "f5_b_train = np.array(f5_b_train)\n",
    "f5_m_train = np.array(f5_m_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4054e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 224, 224, 3)\n",
      "(901, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f1_b_train.shape)\n",
    "print(f1_m_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f619f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:10<00:00, 70.57it/s]\n",
      "100%|██████████| 597/597 [00:08<00:00, 68.24it/s]\n",
      "100%|██████████| 659/659 [00:09<00:00, 70.65it/s]\n",
      "100%|██████████| 679/679 [00:09<00:00, 69.18it/s]\n",
      "100%|██████████| 770/770 [00:11<00:00, 69.23it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_b_test, f1_m_test = Dataset_loader('data/fold1/test/200X', 224)\n",
    "f1_b_test = np.array(f1_b_test)\n",
    "f1_m_test = np.array(f1_m_test)\n",
    "\n",
    "f2_b_test, f2_m_test = Dataset_loader('data/fold2/test/200X', 224)\n",
    "f2_b_test = np.array(f2_b_test)\n",
    "f2_m_test = np.array(f2_m_test)\n",
    "\n",
    "f3_b_test, f3_m_test = Dataset_loader('data/fold3/test/200X', 224)\n",
    "f3_b_test = np.array(f3_b_test)\n",
    "f3_m_test = np.array(f3_m_test)\n",
    "\n",
    "f4_b_test, f4_m_test = Dataset_loader('data/fold4/test/200X', 224)\n",
    "f4_b_test = np.array(f4_b_test)\n",
    "f4_m_test = np.array(f4_m_test)\n",
    "\n",
    "f5_b_test, f5_m_test = Dataset_loader('data/fold5/test/200X', 224)\n",
    "f5_b_test = np.array(f5_b_test)\n",
    "f5_m_test = np.array(f5_m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ab92b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train = np.concatenate((f1_b_train, f2_b_train, f3_b_train, f4_b_train, f5_b_train), axis=0)\n",
    "m_train = np.concatenate((f1_m_train, f2_m_train, f3_m_train, f4_m_train, f5_m_train), axis=0)\n",
    "b_test = np.concatenate((f1_b_test, f2_b_test, f3_b_test, f4_b_test, f5_b_test), axis = 0)\n",
    "m_test = np.concatenate((f1_m_test, f2_m_test, f3_m_test, f4_m_test, f5_m_test), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2539f9",
   "metadata": {},
   "source": [
    "### Create Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25bbdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train_label = np.zeros(len(b_train))\n",
    "m_train_label = np.ones(len(m_train))\n",
    "b_test_label = np.zeros(len(b_test))\n",
    "m_test_label = np.ones(len(m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f230d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data \n",
    "X_train = np.concatenate((b_train, m_train), axis = 0)\n",
    "Y_train = np.concatenate((b_train_label, m_train_label), axis = 0)\n",
    "X_test = np.concatenate((b_test, m_test), axis = 0)\n",
    "Y_test = np.concatenate((b_test_label, m_test_label), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0923fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train = X_train[s]\n",
    "Y_train = Y_train[s]\n",
    "\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "Y_test = Y_test[s]\n",
    "\n",
    "# To categorical\n",
    "Y_train = to_categorical(Y_train, num_classes= 2)\n",
    "Y_test = to_categorical(Y_test, num_classes= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b3ca3",
   "metadata": {},
   "source": [
    "### Train and Evalutation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d139a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X_train, Y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68feb183",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ae225cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# Using original generator\n",
    "train_generator = ImageDataGenerator(\n",
    "        zoom_range=2,  # set range for random zoom\n",
    "        rotation_range = 90,\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True,  # randomly flip images\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08a1ab",
   "metadata": {},
   "source": [
    "### Model: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6412cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 13s 0us/step\n",
      "74850304/74836368 [==============================] - 13s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 7, 7, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1920)              7680      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3842      \n",
      "=================================================================\n",
      "Total params: 18,333,506\n",
      "Trainable params: 18,100,610\n",
      "Non-trainable params: 232,896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callter/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "resnet = DenseNet201(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "model = build_model(resnet ,lr = 1e-4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e32e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Reducer\n",
    "learn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n",
    "                                  verbose=1,factor=0.2, min_lr=1e-7)\n",
    "\n",
    "# Checkpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffeb7ff",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33665252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "num_classes = 2\n",
    "def cnn(train_X, test_X, train_Y, test_Y, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), strides = (1,1), padding='same', \n",
    "                 input_shape=x_train.shape[1:]))  # 第一层需要指出图像的大小\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    model.add(Conv2D(64, (5, 5), strides = (1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    model.add(Conv2D(128, (5, 5), strides = (1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    lr=0.01\n",
    "    epoch = 5\n",
    "    opt = keras.optimizers.rmsprop(lr, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    # here we use the test_set as the validation_set    \n",
    "    model.fit(train_X,train_Y,batch_size=128,epochs=epoch,verbose=2,\n",
    "                validation_data=(test_X,test_Y))\n",
    "    score = model.evaluate(test_X,test_Y,verbose=0)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff27200",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b41b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
